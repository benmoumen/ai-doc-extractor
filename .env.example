# AI Data Extractor - Environment Variables
# Copy this file to .env and fill in your actual values

# =============================================================================
# AI API KEYS (Required)
# =============================================================================
GROQ_API_KEY=your_groq_api_key_here
MISTRAL_API_KEY=your_mistral_api_key_here

# =============================================================================
# APPLICATION SETTINGS
# =============================================================================
ENVIRONMENT=development
DEBUG=true
APP_NAME="AI Data Extractor"
APP_VERSION=0.0.1

# =============================================================================
# SECURITY CONFIGURATION
# =============================================================================
# File upload limits
MAX_FILE_SIZE_MB=10

# Rate limiting
RATE_LIMIT_REQUESTS=100

# API key authentication (set to true for production)
ENABLE_API_KEY_AUTH=false
API_KEYS=your-secure-api-key-here,another-key-here

# CORS origins (comma-separated)
CORS_ORIGINS=http://localhost:3000,http://127.0.0.1:3000

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================
LOG_LEVEL=INFO
LOG_FILE=/app/logs/app.log
ENABLE_REQUEST_LOGGING=true
ENABLE_PERFORMANCE_LOGGING=true

# =============================================================================
# DATABASE CONFIGURATION (SQLite)
# =============================================================================
# SQLite database path (relative to application root)
DATABASE_PATH=data/schemas.db

# =============================================================================
# PERFORMANCE SETTINGS
# =============================================================================
# Image processing
MAX_IMAGE_DIMENSION=4096
IMAGE_COMPRESSION_QUALITY=95
PDF_DPI=200

# Request handling
RESPONSE_TIMEOUT=60
MAX_CONCURRENT_REQUESTS=10

# Caching
CACHE_TTL_SECONDS=3600
ENABLE_RESPONSE_CACHING=true

# =============================================================================
# AI MODEL CONFIGURATION
# =============================================================================
DEFAULT_AI_PROVIDER=groq
DEFAULT_AI_MODEL=meta-llama/llama-4-scout-17b-16e-instruct
AI_TEMPERATURE=0.1
AI_MAX_RETRIES=3
AI_RETRY_DELAY=1.0
AI_REQUEST_TIMEOUT=30

# =============================================================================
# MONITORING & OBSERVABILITY
# =============================================================================
ENABLE_METRICS=true
METRICS_PORT=9090
ENABLE_HEALTH_CHECKS=true
ENABLE_TRACING=false
TRACING_SAMPLE_RATE=0.1


# =============================================================================
# DOCKER & DEPLOYMENT SETTINGS
# =============================================================================
# Python settings
PYTHONUNBUFFERED=1

# API server
API_PORT=8000
API_HOST=0.0.0.0

# Frontend URLs (for CORS and integration)
NEXT_PUBLIC_API_URL=http://localhost:8000
NEXT_PUBLIC_BACKEND_URL=http://backend:8000

# =============================================================================
# PRODUCTION NOTES
# =============================================================================
# For production deployment:
# 1. Set ENVIRONMENT=production
# 2. Set DEBUG=false
# 3. Set ENABLE_API_KEY_AUTH=true and provide secure API_KEYS
# 4. Set LOG_LEVEL=WARNING or ERROR
# 5. Configure proper CORS_ORIGINS for your internal network
# 6. Ensure all AI API keys (GROQ_API_KEY, MISTRAL_API_KEY) are set with real values
# 7. Verify DATABASE_PATH points to a persistent location
# 8. Use docker volumes or bind mounts to ensure database persistence
# 9. Consider enabling ENABLE_TRACING=true for observability if needed
# 10. No external databases (PostgreSQL/Redis) or reverse proxies (nginx) required