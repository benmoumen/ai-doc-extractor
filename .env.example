# AI Data Extractor - Environment Variables
# Copy this file to .env and fill in your actual values

# =============================================================================
# AI API KEYS (Required)
# =============================================================================
GROQ_API_KEY=your_groq_api_key_here
MISTRAL_API_KEY=your_mistral_api_key_here

# =============================================================================
# APPLICATION SETTINGS
# =============================================================================
ENVIRONMENT=development
DEBUG=true
APP_NAME="AI Data Extractor"
APP_VERSION=0.0.1

# =============================================================================
# SECURITY CONFIGURATION
# =============================================================================
# File upload limits
MAX_FILE_SIZE_MB=10

# Rate limiting
RATE_LIMIT_REQUESTS=100

# Security: CORS origins only (no API key auth implemented)

# CORS origins (comma-separated)
CORS_ORIGINS=http://localhost:3000,http://127.0.0.1:3000

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================
LOG_LEVEL=INFO
LOG_FILE=/app/logs/app.log
ENABLE_REQUEST_LOGGING=true

# =============================================================================
# DATABASE CONFIGURATION (SQLite)
# =============================================================================
# Database location: ./data/schemas.db (not configurable)

# =============================================================================
# PERFORMANCE SETTINGS
# =============================================================================
# Image processing
MAX_IMAGE_DIMENSION=4096
IMAGE_COMPRESSION_QUALITY=95
PDF_DPI=200

# Request handling
RESPONSE_TIMEOUT=60
MAX_CONCURRENT_REQUESTS=10

# Caching
CACHE_TTL_SECONDS=3600
ENABLE_RESPONSE_CACHING=true

# =============================================================================
# AI MODEL CONFIGURATION
# =============================================================================
DEFAULT_AI_PROVIDER=groq
DEFAULT_AI_MODEL=meta-llama/llama-4-scout-17b-16e-instruct
AI_TEMPERATURE=0.1
AI_MAX_RETRIES=3
AI_RETRY_DELAY=1.0
AI_REQUEST_TIMEOUT=30

# =============================================================================
# MONITORING & OBSERVABILITY
# =============================================================================
ENABLE_HEALTH_CHECKS=true
ENABLE_TRACING=false
TRACING_SAMPLE_RATE=0.1


# =============================================================================
# DOCKER & DEPLOYMENT SETTINGS
# =============================================================================
# Python settings
PYTHONUNBUFFERED=1

# API server
API_PORT=8000
API_HOST=0.0.0.0

# Frontend URLs (for CORS and integration)
NEXT_PUBLIC_API_URL=http://localhost:8000
NEXT_PUBLIC_BACKEND_URL=http://backend:8000

# =============================================================================
# PRODUCTION DEPLOYMENT CHECKLIST
# =============================================================================
# Before deploying to production:
# 1. ✅ Set real API keys for GROQ_API_KEY and MISTRAL_API_KEY
# 2. ✅ Set proper CORS_ORIGINS for your internal domains
# 3. ✅ Ensure LOG_LEVEL is WARNING or ERROR for production
# 4. ✅ Set ENABLE_API_KEY_AUTH=true
# 6. ✅ Adjust MAX_CONCURRENT_REQUESTS based on your server capacity
# 7. ✅ Test with your internal network configuration
# 8. ✅ Ensure SQLite database directory has proper permissions